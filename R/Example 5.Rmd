
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
set.seed(303203)
```

## Question 1 (2 points)

In a previous week we used the Laplace distribution as a candidate distribution for the standard Normal $N(0,1)$ distribution using an accept-reject algorithm.

Recall that the probability distribution for a standard Normal is given by:

$$f(x) = \frac{1}{\sqrt{2 \pi}} \exp\left\{ - \frac{x^2}{2} \right\}$$

and the Laplace is given by
$$g(x) = \frac{1}{2} \exp\left\{- |x| \right\}$$

And here is a source of Laplace distributed random variables.

```{r}
rlaplace <- function(n, mean = 0) {
  s <- 2 * rbinom(n, size = 1, p = 0.5) - 1
  m <- rexp(n) 
  s * m + mean
}
```

Implement an importance sampling algorithm for standard Normals using the Laplace distribution as the envelope distribution in order to estimate

$$E(X^2)$$
where $X \sim N(0, 1)$. Use 1000 samples and provide a 95\% confidence interval for $E(X^2)$.

Answer:
```{r}
func <- function(y) { (1/2) * exp(- abs(y))}
y <- rlaplace(1000)
est_x2 <- mean(y^2 * dnorm(y) / func(y))
est_x2
t.test(y^2 * dnorm(y) / func(y))$conf.int
```



## Question 2 (5 pts)

Consider the density (known up to a constant) given by:

$$f(x) \propto \sin(\pi  x^2), \quad 0 < x < 1$$

```{r}
curve(sin(pi * x^2), ylab = "f*(x)")
```

### Part (a) (2 pts)

We want to estimate $E(X)$ using importance sampling (resampling).

Using a uniform [0, 1] distribution as the envelope, use (reweighted) importance sampling to estimate $E(X)$. Estimate the variance of the **estimator** (we'll compare it to another estimator in part (b)).

Answer:
```{r}
f <- function(x) { sin(pi * x^2) }
us <- runif(10000)
ratio <- f(us) / 1
reweights <- ratio / sum(ratio)
uniform <- us * reweights * 10000
mean(uniform) # estimate
var(uniform) # variance of the estimator
```



### Part (b) (3 pt)

The uniform distribution is a special case of the [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution) with parameters $\alpha = \beta = 1$. It works as an envelope, but it does not very carefully follow the target function: 
$$E(X) \propto \int_0^1 x \sin(\pi x^2) \, dx$$
```{r}
curve(x * sin(pi * x^2))
```

Propose a set of parameters $\alpha$ and $\beta$ that leads to a better envelope distribution. Use this distribution (see the `rbeta` function) to implement importance sampling to estimate $E(X)$ and the variance of the estimator. Did this estimator have lower variance than the estimator based on the uniform candidate?

Useful tip: A Beta($\alpha, \beta$) with $\alpha > 1$ and $\beta > 1$ will have a mode at $(\alpha - 1) / (\alpha + \beta - 2)$. This can be useful to graph candidate distributions against the target:

```{r}
## target function has a mode at approximately 0.76
target_height <- 0.76 * sin(pi * 0.76^2)

## candidate beta distribution alpha = beta = 2, so a mode at 1/2
cand_height <- dbeta(1/2, 2, 2)

tc_ratio <- target_height/cand_height

curve(x * sin(pi * x^2))
curve(tc_ratio * dbeta(x, 2, 2), add = TRUE, col = "red")
```
Answer:
```{r}
beta_set <- seq(1, 3, length.out = 20)
alpha_set <- 3 * beta_set - 2
curve(x * f(x)) 
h_0.76 <- 0.76 * f(0.76) 
colors <- rainbow(30)

for (i in 1:30) {
  scale <- h_0.76 / dbeta(0.76, alpha_set[i], beta_set[i])
  curve(scale * dbeta(x, alpha_set[i], beta_set[i]), add = TRUE, col = colors[i])
}

beta <- beta_set[13] # similar curve
alpha <- 3 * beta - 2 
scale <- h_0.76 / dbeta(0.76, alpha, beta)

curve(x * f(x))
curve(scale * dbeta(x, alpha, beta), col = "blue", add = TRUE)

b <- rbeta(10000, alpha, beta)
ratios <- f(b) / dbeta(b, alpha, beta)
beta_est <- b * ratios / sum(ratios) * 10000
mean(beta_est) # estimate
var(beta_est) # variance of estimator
# Yes, this estimator have lower variance than the estimator based on the uniform candidate
```



## Question 3 (4 pts)

Consider sampling $n$ pairs $(Y_i, X_i)$ from a very large population of size $N$. We will assume that the population is so large that we can treat $n/N \approx 0$, so that all pairs in our sample are effectively independent.

```{r}
xy <- read.csv("xy.csv")
ggplot(xy, aes(x = x, y = y)) + geom_point()
```

For the population, you want to relate $Y$ and $X$ as a linear function:
$$Y_i = \beta_0 + \beta_1 X_i + R_i$$
where 
\[
\begin{aligned}
\beta_1 &= \frac{\text{Cov}(X,Y)}{\text{Var}(X)} \\
\beta_0 &= E(Y) - \beta_1 E(X) \\
R_i &= Y_i - \beta_0 - \beta_1 X_i
\end{aligned}
\]

The the line described by $\beta_0$ and $\beta_1$ is the "population regression line". We don't get to observe $R_i$ for our sample, but we can estimate $\beta_0$ and $\beta_1$ to get estimates of $R_i$.



### Part (a) (2 points)

The `lm` function in R can estimate $\beta_0$ and $\beta_1$ using sample means and variances. Since these estimators are based on sample means, we can use the **central limit theorem** to justify confidence intervals for $\beta_0$ and $\beta_1$ (we won't do so rigorously in this setting).

Use the `lm` function to estimate $\beta_0$ and $\beta_1$. Apply the `confint` function to the results to get 95% confidence intervals for the $\beta_1$ parameter.

The estimated residuals ($\hat R_i$) can be found by applying the `resid` function to the result of `lm`. Provide a density plot of these values (see `geom_density`). Do they give you any reason to be concerned about the validity of the Central Limit Theorem approximation?

Answer:
```{r}
mod <- lm(y ~ x, data = xy)
confint(mod)[2, ]
ggplot(data.frame(residuals = resid(mod)), aes(x = residuals)) + geom_density(fill = "red")
# the distribution is right skewed. As observed when exploring confidence intervals with various data distributions, sampling distributions of the mean based on non-symmetric or heavy-tailed distributions may not be accurately described by a Normal approximation, particularly at small or moderate sample sizes. So there may be reason to question whether a sample size of 80 is large enough for a reliable approximation using the Central Limit Theorem.
```


### Part (b) (2 pts)

You can use the `coef` function to get just the estimators $\hat \beta_0$ and $\hat \beta_1$. Use the `boot` package to get basic and percentile confidence intervals for just $\beta_1$. You will need to write a custom function to give as the `statistic` argument to `boot`. Use at least 1000 bootstrap samples. You can use `boot.ci` for the confidence intervals.

Comment on the assumptions required for the bootstrap intervals.

Answer:
```{r}
q3_stat <- function(data, index) {
  xystar <- data[index, ]
  modstar <- lm(y ~ x, data = xystar)
  coef(modstar)[2]
}
library(boot)

q3_boot <- boot(xy, q3_stat, R = 1000)

(q3_boot_ci <- boot.ci(q3_boot, type = c('basic', 'perc')))

```
The primary assumption here is that the sample size is sufficiently large to estimate \( F_{XY} \) using the empirical CDF \( \hat{F}_{XY} \). Similar to the Central Limit Theorem, this is a large-sample assumption but does not rely on any specific functional form for the distribution of \( \hat{\beta}_1 \). This assumption about sample size also implies that the observed statistic is close to the true \( \beta_1 \). Additionally, it is assumed that there are enough bootstrap replications (1000) to adequately approximate the distribution of \( \hat{\beta}_1 \).

## Question 4 (7 pts)

Suppose that instead of sampling pairs, we first identified some important values of $x$ that we wanted to investigate. Treating these values as fixed, we sampled a varying number of $Y_i$ for each $x$ value. For these data, we'll attempt to model the conditional distribution of $Y \, | \, x$ as:
$$Y \, | \, x = \beta_0 + \beta_1 x + \epsilon$$
where $\epsilon$ epsilon is assumed to be symmetric about zero (therefore, $E(\epsilon) = 0$) and the variance of $\epsilon$ does not depend on $x$ (a property called "homoskedasticity"). These assumptions are very similar to the population regression line model (as $E(R_i) = 0$ by construction), but cover the case where we want to design the study on particular values (a common case is a randomized trial where $x$ values are assigned from a known procedure and $Y$ is measured after).

### Part (a) (3 pts)

Let's start with some stronger assumptions and then relax them in the subsequent parts of the question.

The assumptions that support the Central Limit Theorem in Question 1 can also be used to assume that $\epsilon \sim N(0, \sigma^2)$ so that:

$$Y \mid x \sim N(\beta_0 + \beta_1 x, \sigma^2)$$

We've noticed that the Normal distribution has "light tails" and assumptions based on Normality can be sensitive to outliers.

Instead, suppose we we model $\epsilon$ with a scaled $t$-distribution with 4 degrees of freedom (i.e., has fatter tails than the Normal distribution): 
$$\epsilon \sim \frac{\sigma}{\sqrt{2}} t(4) \Rightarrow \text{Var}(\epsilon) = \sigma^2$$
(The $\sqrt{2}$ is there just to scale the $t$-distribution to have a variance of 1. More generally, if we picked a differed degrees of freedom parameter $v$, this would be replaced with $\sqrt{v/(v-2)}$.)


One way to get an estimate of the distribution of $\hat \beta_1$ is the following algorithm:


1. Estimate $\beta_0$, $\beta_1$, and $\sigma$ using linear regression (you can get the $\hat \sigma$ using `summary(model)$sigma`),
2. For all the $x_i$ in the sample, generate $\hat y_i = \hat \beta_0 + \hat \beta_1 x_i$ (you can use `predict(model)` to get $\hat y$)
3. For $B$ replications, generate $Y_i^* = \hat y_i + \epsilon_i*$, where 
$$\epsilon^* \sim \frac{\hat \sigma}{\sqrt{2}} t(4)$$
4.  For each replication, use linear regression to estimate $\hat \beta_1^*$. 
5.  Use the $\alpha/2$ and $1 - \alpha/2$ quantiles of the bootstrap distribution to get the confidence intervals:
$$[2 \hat \beta_1 - \hat \beta_1^*(1 - \alpha/2), 2 \hat \beta_1 - \hat \beta_1^*(\alpha/2)]$$
To avoid double subscripts I've written $\hat \beta^*_1(1 - \alpha/2)$ as the upper $1 - \alpha/2$ quantile of the bootstrap (and likewise for the lower $\alpha/2$ quantile).

You may note that this is a "basic" basic bootstrap interval. In fact, this procedure (fitting parameters, then simulating from a model) is known as a **parametric bootstrap**.

Use the algorithm above to generate a confidence interval for $\beta_1$. Compare it to the fully parametric interval produced in Question 1(a). Which is larger or smaller?

Note: The `boot` function does have the option of performing a parametric bootstrap using a user supplied `rand.gen` function. Feel free to use this functionality, but you may find it easier to implement the algorithm directly.

Answer:
```{r}
n <- dim(xy)[1]
mod <- lm(y ~ x, data = xy)
yhat <- predict(mod)
ehat <- xy$y - yhat
beta1 <- coef(mod)[2]
sigma <- summary(mod)$sigma
bstar <- replicate(1000, {
  estar <- sigma / sqrt(2) * rt(n, df = 4)
  ystar <- yhat + estar
  coef(lm(ystar ~ xy$x))[2]
})

(q4a_ci <- 2 * coef(mod)[2] - quantile(bstar, c(0.975, 0.025)))

diff(q4a_ci)

confint(mod)[2, ] %>% diff
```


This interval appears to be slightly wider than the Normal theory intervals. This is expected, as the t-distribution differs from the Normal distribution primarily in its tails, with the t-distribution having slightly wider tails. This additional probability in the tails results in marginally larger confidence intervals.

### Part (b) (3 pts)

As an alternative to sampling from an assumed distribution for $\epsilon$, we can replace step (3) in the previous algorithm with 

3. Draw a sample (with replacement) from $\hat \epsilon_i$ and make $Y_i^* = \hat y_i + \epsilon_i^*$

Implement this version of a parametric bootstrap. Feel free to use the `boot` package. 

Answer:
```{r}
q4_b_stat <- function(data, index) {
  ystar <- yhat + data[index]
  mod <- lm(ystar ~ xy$x)
  coef(mod)[2]
}
q4_b_boot <- boot(ehat, q4_b_stat, R = 1000)
q4b_ci <- boot.ci(q4_b_boot, type = "basic")

q4b_ci
```



### Part (c) (1 pt)

Discuss the differences in the four types of intervals we created (fully parametric in 1(a), non-parametric bootstrap in 1(b), two variations of parametric bootstrap in 2(a) and 2(b)). When analyzing a particular data set, when would you pick one method over the another methods?

Answer:
The four confidence intervals—fully parametric (1a), non-parametric bootstrap (1b), and two parametric bootstraps (2a and 2b)—differ in assumptions and suitability for various data characteristics. The fully parametric interval (1a) is efficient for large, Normal data, while the non-parametric bootstrap (1b) is robust and ideal for smaller or skewed data as it avoids distributional assumptions. The parametric bootstraps (2a and 2b) strike a balance, with 2a assuming a t-distribution for heavier tails and 2b resampling residuals to add robustness without strict parametric assumptions. For large, Normal data, 1(a) is computationally convenient; for non-Normal or uncertain data, 1(b) or 2(b) offer flexibility.

## Question 5 (2 pts)

Read the paper "THE RISK OF CANCER ASSOCIATED WITH SPECIFIC MUTATIONS OF BRCA1 AND BRCA2 AMONG ASHKENAZI JEWS." Briefly summarize the paper. Make sure to discuss the research question, data source, methods, and results. How did the authors use the bootstrap procedure in this paper?

Answer:
The study investigates the risk of breast, ovarian, and prostate cancer associated with specific BRCA1 and BRCA2 mutations in Ashkenazi Jews. Researchers collected blood samples and family cancer histories from 5,318 Jewish participants in Washington, D.C., identifying 120 mutation carriers. Using gene sequencing data and cancer history from relatives, they estimated cancer risks by age 70 for carriers: 56% for breast cancer, 16% for ovarian cancer, and 16% for prostate cancer. To calculate confidence intervals for these risk estimates, the authors used a bootstrap procedure with 1,000 replicates, yielding percentile intervals. For example, breast cancer risk for relatives of carriers was estimated between 23% and 44%, while for non-carriers, the interval was between 4% and 5%, with similar results reported for ovarian cancer.

